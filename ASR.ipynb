{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c98fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3e18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('txt_de.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9495f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vielen Dank, Chris. Es ist mir wirklich eine E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Das meine ich ernst, teilweise deshalb — weil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jetzt muss ich meine Schuhe ausziehen, um über...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ich erzähle Ihnen mal eine Geschichte, dann ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eine wahre Geschichte — kein Wort daran ist er...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt\n",
       "0  Vielen Dank, Chris. Es ist mir wirklich eine E...\n",
       "1  Das meine ich ernst, teilweise deshalb — weil ...\n",
       "2  Jetzt muss ich meine Schuhe ausziehen, um über...\n",
       "3  Ich erzähle Ihnen mal eine Geschichte, dann ve...\n",
       "4  Eine wahre Geschichte — kein Wort daran ist er..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1922a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf6f2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = os.listdir('wav/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16863edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67933543",
   "metadata": {},
   "outputs": [],
   "source": [
    "notation = df['txt'][0:49].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "726c631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "for i,j in zip(wav,notation):\n",
    "    data.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3152e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.DataFrame(data,columns=['file_name','notation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b943e4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>notation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted_48.wav</td>\n",
       "      <td>Vielen Dank, Chris. Es ist mir wirklich eine E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted_3.wav</td>\n",
       "      <td>Das meine ich ernst, teilweise deshalb — weil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ted_12.wav</td>\n",
       "      <td>Jetzt muss ich meine Schuhe ausziehen, um über...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted_13.wav</td>\n",
       "      <td>Ich erzähle Ihnen mal eine Geschichte, dann ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ted_2.wav</td>\n",
       "      <td>Eine wahre Geschichte — kein Wort daran ist er...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name                                           notation\n",
       "0  ted_48.wav  Vielen Dank, Chris. Es ist mir wirklich eine E...\n",
       "1   ted_3.wav  Das meine ich ernst, teilweise deshalb — weil ...\n",
       "2  ted_12.wav  Jetzt muss ich meine Schuhe ausziehen, um über...\n",
       "3  ted_13.wav  Ich erzähle Ihnen mal eine Geschichte, dann ve...\n",
       "4   ted_2.wav  Eine wahre Geschichte — kein Wort daran ist er..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f84831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06427468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training set: 44\n",
      "Size of the training set: 5\n"
     ]
    }
   ],
   "source": [
    "split = int(len(df_f) * 0.90)\n",
    "df_train = df_f[:split]\n",
    "df_val = df_f[split:]\n",
    "\n",
    "print(f\"Size of the training set: {len(df_train)}\")\n",
    "print(f\"Size of the training set: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a26c0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', ' '] (size =31)\n"
     ]
    }
   ],
   "source": [
    "# The set of characters accepted in the transcription.\n",
    "characters = [x for x in \"abcdefghijklmnopqrstuvwxyz'?! \"]\n",
    "# Mapping characters to integers\n",
    "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8be2a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An integer scalar Tensor. The window length in samples.\n",
    "frame_length = 256\n",
    "# An integer scalar Tensor. The number of samples to step.\n",
    "frame_step = 160\n",
    "# An integer scalar Tensor. The size of the FFT to apply.\n",
    "# If not provided, uses the smallest power of 2 enclosing frame_length.\n",
    "fft_length = 384\n",
    "\n",
    "\n",
    "def encode_single_sample(wav_file, label):\n",
    "    ###########################################\n",
    "    ##  Process the Audio\n",
    "    ##########################################\n",
    "    # 1. Read wav file\n",
    "    file = tf.io.read_file( 'wav/'+wav_file)\n",
    "    # 2. Decode the wav file\n",
    "    audio, _ = tf.audio.decode_wav(file)\n",
    "    audio = tf.squeeze(audio, axis=-1)\n",
    "    # 3. Change type to float\n",
    "    audio = tf.cast(audio, tf.float32)\n",
    "    # 4. Get the spectrogram\n",
    "    spectrogram = tf.signal.stft(\n",
    "        audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
    "    )\n",
    "    # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.math.pow(spectrogram, 0.5)\n",
    "    # 6. normalisation\n",
    "    means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
    "    stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
    "    spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
    "    ###########################################\n",
    "    ##  Process the label\n",
    "    ##########################################\n",
    "    # 7. Convert label to Lower case\n",
    "    label = tf.strings.lower(label)\n",
    "    # 8. Split the label\n",
    "    label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
    "    # 9. Map the characters in label to numbers\n",
    "    label = char_to_num(label)\n",
    "    # 10. Return a dict as our model is expecting two inputs\n",
    "    return spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e54dd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "# Define the trainig dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_train[\"file_name\"]), list(df_train[\"notation\"]))\n",
    ")\n",
    "train_dataset = (\n",
    "    train_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "# Define the validation dataset\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (list(df_val[\"file_name\"]), list(df_val[\"notation\"]))\n",
    ")\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .padded_batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52308549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CTCLoss(y_true, y_pred):\n",
    "    # Compute the training-time loss value\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d27aab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DeepSpeech_2\"\n",
      "______________________________________________________________________________________________________________\n",
      "Layer (type)                                     Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      "input (InputLayer)                               [(None, None, 193)]                         0                \n",
      "______________________________________________________________________________________________________________\n",
      "expand_dim (Reshape)                             (None, None, 193, 1)                        0                \n",
      "______________________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                                  (None, None, 97, 32)                        14432            \n",
      "______________________________________________________________________________________________________________\n",
      "conv_1_bn (BatchNormalization)                   (None, None, 97, 32)                        128              \n",
      "______________________________________________________________________________________________________________\n",
      "conv_1_relu (ReLU)                               (None, None, 97, 32)                        0                \n",
      "______________________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                                  (None, None, 49, 32)                        236544           \n",
      "______________________________________________________________________________________________________________\n",
      "conv_2_bn (BatchNormalization)                   (None, None, 49, 32)                        128              \n",
      "______________________________________________________________________________________________________________\n",
      "conv_2_relu (ReLU)                               (None, None, 49, 32)                        0                \n",
      "______________________________________________________________________________________________________________\n",
      "reshape (Reshape)                                (None, None, 1568)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)                  (None, None, 1024)                          6395904          \n",
      "______________________________________________________________________________________________________________\n",
      "dropout (Dropout)                                (None, None, 1024)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)                  (None, None, 1024)                          4724736          \n",
      "______________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                              (None, None, 1024)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional)                  (None, None, 1024)                          4724736          \n",
      "______________________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                              (None, None, 1024)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional)                  (None, None, 1024)                          4724736          \n",
      "______________________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                              (None, None, 1024)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional)                  (None, None, 1024)                          4724736          \n",
      "______________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                                  (None, None, 1024)                          1049600          \n",
      "______________________________________________________________________________________________________________\n",
      "dense_1_relu (ReLU)                              (None, None, 1024)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)                              (None, None, 1024)                          0                \n",
      "______________________________________________________________________________________________________________\n",
      "dense (Dense)                                    (None, None, 32)                            32800            \n",
      "==============================================================================================================\n",
      "Total params: 26,628,480\n",
      "Trainable params: 26,628,352\n",
      "Non-trainable params: 128\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
    "    \"\"\"Model similar to DeepSpeech2.\"\"\"\n",
    "    # Model's input\n",
    "    input_spectrogram = layers.Input((None, input_dim), name=\"input\")\n",
    "    # Expand the dimension to use 2D CNN.\n",
    "    x = layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
    "    # Convolution layer 1\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 41],\n",
    "        strides=[2, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_1\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_1_relu\")(x)\n",
    "    # Convolution layer 2\n",
    "    x = layers.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=[11, 21],\n",
    "        strides=[1, 2],\n",
    "        padding=\"same\",\n",
    "        use_bias=False,\n",
    "        name=\"conv_2\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
    "    x = layers.ReLU(name=\"conv_2_relu\")(x)\n",
    "    # Reshape the resulted volume to feed the RNNs layers\n",
    "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
    "    # RNN layers\n",
    "    for i in range(1, rnn_layers + 1):\n",
    "        recurrent = layers.GRU(\n",
    "            units=rnn_units,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            use_bias=True,\n",
    "            return_sequences=True,\n",
    "            reset_after=True,\n",
    "            name=f\"gru_{i}\",\n",
    "        )\n",
    "        x = layers.Bidirectional(\n",
    "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
    "        )(x)\n",
    "        if i < rnn_layers:\n",
    "            x = layers.Dropout(rate=0.5)(x)\n",
    "    # Dense layer\n",
    "    x = layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
    "    x = layers.ReLU(name=\"dense_1_relu\")(x)\n",
    "    x = layers.Dropout(rate=0.5)(x)\n",
    "    # Classification layer\n",
    "    output = layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt, loss=CTCLoss)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Get the model\n",
    "model = build_model(\n",
    "    input_dim=fft_length // 2 + 1,\n",
    "    output_dim=char_to_num.vocabulary_size(),\n",
    "    rnn_units=512,\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6be1f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# A callback class to output a few transcriptions during training\n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "                )\n",
    "                targets.append(label)\n",
    "        wer_score = wer(targets, predictions)\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
    "        print(\"-\" * 100)\n",
    "        for i in np.random.randint(0, len(predictions), 2):\n",
    "            print(f\"Target    : {targets[i]}\")\n",
    "            print(f\"Prediction: {predictions[i]}\")\n",
    "            print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of epochs.\n",
    "epochs = 1\n",
    "# Callback function to check transcription on the val set.\n",
    "validation_callback = CallbackEval(validation_dataset)\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[validation_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde815a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
